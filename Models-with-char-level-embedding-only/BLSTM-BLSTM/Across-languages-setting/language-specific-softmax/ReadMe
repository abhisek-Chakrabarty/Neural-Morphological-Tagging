Requirements:
======================

Python 2.7
Keras 1


Training file format: - The training files of the languages belong to same family are to be dumped together. For each language there will be a special character denoting language-id and each word of a particular language should be prefixed and suffixed with the corresponding language-id. For example, '1', '2' and '3' are set as the language-ids of Hindi, Marathi and Sanskrit respectively. Therefore in the training set, each Hindi word, say 'xyz' should be replaced by '1xyz1'.

In the training file, words and their respecive morpholgical tags should be tab separated. After each sentence, there should be a new line. 
The format of the train file is like below:

<id>word1<id>	tag1
<id>word2<id>	tag2
<id>word3<id>	tag3
<id>word4<id>	tag4

<id>word5<id>	tag5
<id>word6<id>	tag6
<id>word7<id>	tag7
<id>word8<id>	tag8
<id>word9<id>	tag9


Test file and development file format: In the test/dev file, after each sentence, there should be a new line. The format is like below:

<id>word1<id>
<id>word2<id>
<id>word3<id>
<id>word4<id>

<id>word5<id>
<id>word6<id>
<id>word7<id>
<id>word8<id>
<id>word9<id>

Across-languages-setting:
=========================
Learning is done on multi-lingual data. There are 2 sets of codes - one for training 2 languages together and another for training 3 lnguages together. But, it can be generalized i.e. allowing arbitrary number of languages for training.

***Note that the code for language universal softmax setting is same as that of the single language setting. Only the training files of the candidate languages are to be dumped together and each word should be prefixed and suffixed by the corresponding language-id.

The value of the hyper-parameters are stored in the "parameters" file which denote the following:

The first line should be the cell type of the character level network. It should be BLSTM.
The second line should be the maximum word length in number of characters. For the words having number of characters more than this value, the excess characters will be truncated out. In our experiments, We set this to 25.
The third line should be the number of neurons in the cell of the character level network.
The fourth line should be the cell type of the tag-classification network. It should be BLSTM.
The fifth line should be the number of neurons in the cell of the tag-classification network.
The sixth line should be the number of epochs for training of the network.
The seventh line should be the batch size for training of the network.
The eighth line is the divide file factor. For large size data, creating the data matrices which will be generated while running the code, takes too much time. To reduce the time, we fragment the matrices part-by-part and then dump them in the disk and reload part-by-part. For our experiments we kept this value as 2000. It's user's choice to set this value. Normally set this value in terms of thousands i.e. 1000/2000/3000.


How to run the code:

Place all python files (main.py, preprocessing.py, models.py, load_data.py, f_measure_accuracy.py), parameters file, train file, test file in the same directory.

To train a model run the following command in gnu terminal.

python main.py parameters train-file

For prediction, run the following command in gnu terminal.

python main.py parameters train-file test-file

Output will be saved in test-file_output

To evaluate the accuracy of a trained model on a test set, run the following command in gnu terminal.

python main.py parameters train-file test-file

Here the format of the test file is same as the train file i.e. words and their gold tags are TAB separated. After each sentence, there is a line gap.

